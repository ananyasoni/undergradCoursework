{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing\n",
    "\n",
    "In this homework, you'll implement, document, and test a series of functions to apply control structures and data structures to solve problems mimicking different types of data cleanup and processing. Later, we'll learn how to use more real-world library functions to complete these tasks more effectively.\n",
    "\n",
    "For each question, you'll be asked to **implement a function**, **document it** with a docstring, and **test it** with doctests. For specific guidance, search for the \"style guide\" on the course website. Generally:\n",
    "\n",
    "- To fulfill the documentation requirements, use your own words to provide a brief description of only the details that a client needs to know to call the function.\n",
    "- To fulfill testing requirements, convert each provided valid function call example into a doctest and additionally write 2 more test cases of your own. You may need to change the given examples slightly to meet doctest requirements.\n",
    "\n",
    "The `run_docstring_examples` function call at the end of each task will only print a message if test cases fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import doctest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outside Sources\n",
    "\n",
    "Update the following Markdown cell to include your name and list your outside sources. Submitted work should be consistent with the curriculum and your sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name**: Ananya Shreya Soni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: `text_normalize`\n",
    "\n",
    "*Text normalization* is the process of removing unwanted characters from a piece of text, such as whitespace or special characters. Write and test a function `text_normalize` that takes a string and returns a new string that keeps only alphabetical characters (ignore whitespace, numbers, non-alphabet characters, etc.) and turns all alphabetical characters to lowercase.\n",
    "\n",
    "- `text_normalize(\"Hello\")` should return `\"hello\"`\n",
    "- `text_normalize(\"Hello!\")` should return `\"hello\"`\n",
    "- `text_normalize(\"heLLo tHEr3!!!\")` should return `\"hellother\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_normalize(text):\n",
    "    \"\"\"\n",
    "    Given text, returns all the characters in that text in lowercase that are in the\n",
    "    alphabet joined together with no whitespace\n",
    "\n",
    "    >>> text_normalize(\"Hello\")\n",
    "    'hello'\n",
    "    >>> text_normalize(\"Hello!\")\n",
    "    'hello'\n",
    "    >>> text_normalize(\"heLLo tHEr3!!!\")\n",
    "    'hellother'\n",
    "    >>> text_normalize(\"\")\n",
    "    ''\n",
    "    >>> text_normalize(\"ANANYA SHREYA SONI\")\n",
    "    'ananyashreyasoni'\n",
    "    >>> text_normalize(\"!!!👩🏽‍💻!!!\")\n",
    "    ''\n",
    "    \"\"\"\n",
    "    alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    normalized_text = ''\n",
    "    for char in text:\n",
    "        char = char.lower()\n",
    "        if (char in alphabet):\n",
    "            normalized_text += char\n",
    "    return normalized_text\n",
    "doctest.run_docstring_examples(text_normalize, globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: `average_tokens_per_line`\n",
    "\n",
    "Write and test a function `average_tokens_per_line` that takes the name of a `.txt` file and returns the average number of tokens per line in the file. For example, if the file `song.txt` contains the text:\n",
    "\n",
    "```\n",
    "Row, row, row your boat\n",
    "Gently down the stream\n",
    "Merrily, merrily, merrily, merrily,\n",
    "Life is but a dream!\n",
    "```\n",
    "\n",
    "The first line has 5 tokens; the second has 4; the third has 4; and the fourth has 5. This gives an average tokens per line of `4.5`.\n",
    "\n",
    "To write additional test cases, create new text files. From the JupyterLab **File** menu, choose **New** and then **Text File**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_tokens_per_line(file):\n",
    "    \"\"\"\n",
    "    Given a text file, returns the average number of tokens per line\n",
    "    (ie: the total number of tokens divided by the total number of lines)\n",
    "\n",
    "    >>> average_tokens_per_line(\"song.txt\")\n",
    "    4.5\n",
    "    >>> average_tokens_per_line(\"empty.txt\")\n",
    "    0\n",
    "    >>> average_tokens_per_line(\"whitespace.txt\")\n",
    "    0\n",
    "    >>> average_tokens_per_line(\"simple.txt\")\n",
    "    1.0\n",
    "    >>> average_tokens_per_line(\"small_dict.txt\")\n",
    "    1.5\n",
    "    \"\"\"\n",
    "    num_lines = 0\n",
    "    num_tokens = 0\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            num_lines += 1\n",
    "            num_tokens += len(line.split())\n",
    "    if num_tokens == 0:\n",
    "        return 0\n",
    "    return num_tokens / num_lines\n",
    "doctest.run_docstring_examples(average_tokens_per_line, globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: `pair_up`\n",
    "\n",
    "When creating and processing datasets, sometimes it's useful to pair-up identifiers with each data element. For this task, you are given some buggy code that is intended to take a set of identifiers and a set of elements and returns a set of every identifier paired with every element. Since sets are unordered, there is no inherent ordering to the tuples in the result set.\n",
    "\n",
    "Your task is to identify and correct the bug, and then explain the bugs you encountered and what drew you to your specific fixes. For this task, you do not need to write additional test cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first bug I encountered was the very first line of the program, result = {}, which is incorrect because result is assigned to an empty dictionary. However as per the spec we want to return a set of tuples not a dictionary so I fixed the first line to be, result = set(). This assigns result to an empty set. The second bug I encountered was the fourth line of the program, result.add(identifier, element). This does not add the tuple (identifier, element) to result but instead tries to add both identifier and element seperately. This causes an error because add only accepts 1 arguement and since we want to add a tuple consisting of the identifier and element I changed the line of code to result.add((identifier, element)) which correctly adds the tuple (identifier, element) to the resulting set of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_up(identifiers, elements):\n",
    "    \"\"\"\n",
    "    Given two sets, returns a set of tuples where each item in the first set is paired with each\n",
    "    item in the second set.\n",
    "\n",
    "    For the doctests, we use the sorted function to ensure a predictable ordering for the tuples\n",
    "    because sets do not generally guarantee a specific ordering.\n",
    "\n",
    "    >>> sorted(pair_up({10, 20}, {5, 6, 7}))\n",
    "    [(10, 5), (10, 6), (10, 7), (20, 5), (20, 6), (20, 7)]\n",
    "    >>> sorted(pair_up({10, 20}, {\"I\", \"am\", \"Groot\"}))\n",
    "    [(10, 'Groot'), (10, 'I'), (10, 'am'), (20, 'Groot'), (20, 'I'), (20, 'am')]\n",
    "    \"\"\"\n",
    "    # bug 1: result = {}\n",
    "    result = set()\n",
    "    for identifier in identifiers:\n",
    "        for element in elements:\n",
    "            # bug 2: result.add(identifier, element)\n",
    "            result.add((identifier, element))\n",
    "    return result\n",
    "\n",
    "\n",
    "doctest.run_docstring_examples(pair_up, globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: `five_number_summary`\n",
    "\n",
    "Write and test a function `five_number_summary` that takes a sorted list of at least 5 numbers and returns a tuple containing the five-number summary of the input: the input list's `(minimum, first-quartile, median, third-quartile, maximum)`. The first quartile is the median of the lower half of the data (including the minimum), and the third quartile is the median of the upper half of the data (including the maximum). The median should be excluded from the calculations of the first and third quartiles.\n",
    "\n",
    "- `five_number_summary([1, 2, 3, 4, 5])` should return `(1, 1.5, 3, 4.5, 5)`\n",
    "- `five_number_summary([1, 1, 1, 1, 1])` should return `(1, 1, 1, 1, 1)`\n",
    "- `five_number_summary([30, 31, 31, 34, 36, 38, 39, 51, 53])` should return `(30, 31, 36, 45, 53)`\n",
    "- `five_number_summary([5, 13, 14, 15, 16, 17, 25])` should return `(5, 13, 15, 17, 25)`\n",
    "- `five_number_summary([5, 12, 12, 13, 13, 15, 16, 26, 26, 29, 29, 30])` should return `(5, 12.5, 15.5, 27.5, 30)`\n",
    "- `five_number_summary([12, 12, 13, 13, 15, 16, 26, 26, 29, 29])` should return `(12, 13, 15.5, 26, 29)`\n",
    "\n",
    "The following examples of invalid function calls should not be tested:\n",
    "\n",
    "- `five_number_summary([1])` since the input list does not have at least five numbers\n",
    "- `five_number_summary([5, 4, 3, 2, 1])` since the input list is not sorted from least to greatest\n",
    "\n",
    "We recommend defining a helper function to find the median of a given list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median(data):\n",
    "    \"\"\"\n",
    "    Given a sorted list of numbers returns the median\n",
    "    \"\"\"\n",
    "    mid_index = ((len(data) - 1) // 2)\n",
    "    if (len(data) % 2 == 0):\n",
    "        return (data[mid_index] + data[mid_index + 1]) / 2\n",
    "    else:\n",
    "        return data[mid_index]\n",
    "\n",
    "def five_number_summary(data):\n",
    "    \"\"\"\n",
    "    Given a sorted list of 5 or more numbers returns a 5 number summary tuple\n",
    "    consisting of the minimum value, first quartile, median, third quartile, and maximum\n",
    "    value\n",
    "\n",
    "    >>> five_number_summary([1, 2, 3, 4, 5])\n",
    "    (1, 1.5, 3, 4.5, 5)\n",
    "    >>> five_number_summary([1, 2, 3, 4, 5, 6])\n",
    "    (1, 2, 3.5, 5, 6)\n",
    "    >>> five_number_summary([0, 0, 0, 0, 0])\n",
    "    (0, 0.0, 0, 0.0, 0)\n",
    "    >>> five_number_summary([0, 0, 0, 0, 0, 0])\n",
    "    (0, 0, 0.0, 0, 0)\n",
    "    >>> five_number_summary([1, 1, 1, 1, 1])\n",
    "    (1, 1.0, 1, 1.0, 1)\n",
    "    >>> five_number_summary([30, 31, 31, 34, 36, 38, 39, 51, 53])\n",
    "    (30, 31.0, 36, 45.0, 53)\n",
    "    >>> five_number_summary([5, 13, 14, 15, 16, 17, 25])\n",
    "    (5, 13, 15, 17, 25)\n",
    "    >>> five_number_summary([5, 12, 12, 13, 13, 15, 16, 26, 26, 29, 29, 30])\n",
    "    (5, 12.5, 15.5, 27.5, 30)\n",
    "    >>> five_number_summary([12, 12, 13, 13, 15, 16, 26, 26, 29, 29])\n",
    "    (12, 13, 15.5, 26, 29)\n",
    "    \"\"\"\n",
    "    mid_index = ((len(data) - 1) // 2)\n",
    "    med = median(data)\n",
    "    if (len(data) % 2 == 0):\n",
    "        first_quartite = median(data[:mid_index + 1])\n",
    "        third_quartile = median(data[mid_index + 1:])\n",
    "    else:\n",
    "        first_quartite = median(data[:mid_index])\n",
    "        third_quartile = median(data[mid_index + 1:])\n",
    "    minimum = data[0]\n",
    "    maximum = data[len(data) - 1]\n",
    "    return (minimum, first_quartite, med, third_quartile, maximum)\n",
    "\n",
    "\n",
    "doctest.run_docstring_examples(five_number_summary, globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: `num_outliers`\n",
    "\n",
    "An *outlier* is an extreme data point that can influence the shape and distribution of numeric data. $x$ is considered an outlier if either:\n",
    "\n",
    "- $x$ is less than the first quartile minus 1.5 times the interquartile range\n",
    "- $x$ is greater than the third quartile plus 1.5 times the interquartile range\n",
    "\n",
    "The *interquartile range* is defined as the third quartile minus the first quartile.\n",
    "\n",
    "Write and test a function `num_outliers` that takes a sorted list of at least five numbers and returns the number of data points that would be considered outliers using your `five_number_summary` to calculate the first and third quartiles.\n",
    "\n",
    "- `num_outliers([1, 2, 3, 4, 5])` should return `0`\n",
    "- `num_outliers([1, 99, 200, 500, 506, 507])` should return `0`\n",
    "- `num_outliers([5, 13, 14, 15, 16, 17, 25])` should return `2` (the outliers are 5 and 25)\n",
    "- `num_outliers([33, 34, 35, 36, 36, 36, 37, 37, 100, 101])` should return `2` (the outliers are 100 and 101)\n",
    "- `num_outliers([8, 10, 10, 11, 11, 12])` should return `1` (the outlier is 8)\n",
    "\n",
    "The following examples of invalid function calls should not be tested:\n",
    "\n",
    "- `num_outliers([3, 3, 3])` input list should contain at least five numbers\n",
    "- `num_outliers([3, 2, 1, 0, 5])` input list should be sorted from least to greatest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_outliers(data):\n",
    "    \"\"\"\n",
    "    Given a sorted list of 5 or more numbers returns the number of data points that\n",
    "    would be considered outliers (note: a data point is considered an outlier if not in\n",
    "    [q1 - 1.5 * interquartile range, q3 + 1.5 * interquartile range])\n",
    "\n",
    "    >>> num_outliers([1, 2, 3, 4, 5])\n",
    "    0\n",
    "    >>> num_outliers([0, 0, 0, 0, 0])\n",
    "    0\n",
    "    >>> num_outliers([0, 0, 0, 0, 0, 0])\n",
    "    0\n",
    "    >>> num_outliers([1, 99, 200, 500, 506, 507])\n",
    "    0\n",
    "    >>> num_outliers([5, 13, 14, 15, 16, 17, 25])\n",
    "    2\n",
    "    >>> num_outliers([33, 34, 35, 36, 36, 36, 37, 37, 100, 101])\n",
    "    2\n",
    "    >>> num_outliers([8, 10, 10, 11, 11, 12])\n",
    "    1\n",
    "    >>> num_outliers([12, 12, 13, 13, 15, 16, 26, 26, 29, 29])\n",
    "    0\n",
    "    >>> num_outliers([30, 31, 31, 34, 36, 38, 39, 51, 100])\n",
    "    1\n",
    "    >>> num_outliers([-45, -30, 47, 47, 48, 48, 48, 49, 49, 49, 50, 50, 50, 50, 51, 51, 51, 52, 52, 52, 53, 53, 150, 170, 200])\n",
    "    5\n",
    "    \"\"\"\n",
    "    _, first_quartile, _, third_quartile, _ = five_number_summary(data)\n",
    "    interquartile_range = third_quartile - first_quartile\n",
    "    count_outliers = 0\n",
    "    min_outlier = first_quartile - 1.5 * interquartile_range\n",
    "    max_outlier = third_quartile + 1.5 * interquartile_range\n",
    "    for x in data:\n",
    "        if x < min_outlier or x > max_outlier:\n",
    "            count_outliers += 1\n",
    "    return count_outliers\n",
    "\n",
    "\n",
    "doctest.run_docstring_examples(num_outliers, globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: `reformat_date`\n",
    "\n",
    "Write and test a function `reformat_date` that takes three strings: a date string, an input date format, and an output date format. This function should return a new date string formatted according to the output date format.\n",
    "\n",
    "A **date string** is a non-empty string of numbers separated by `/`, such as `\"2/20/1991\"` or `\"1991/02/20\"`. The order of date fields (month, day, year) will depend on the date format, and the number of digits for each field can vary but there must be at least one digit for each field.\n",
    "\n",
    "A **date format** is a non-empty string of the date symbols `\"D\"`, `\"M\"`, `\"Y\"` separated by `/`. Assume the date string will match the date formats (share the same number of `/`s), that any date symbol in the output date format will also appear in the input date format, and that date formats do not duplicate date symbols.\n",
    "\n",
    "- `reformat_date(\"12/31/1998\", \"M/D/Y\", \"D/M/Y\")` returns `\"31/12/1998\"`\n",
    "- `reformat_date(\"1/2/3\", \"M/D/Y\", \"Y/M/D\")` returns `\"3/1/2\"`\n",
    "- `reformat_date(\"0/200/4\", \"Y/D/M\", \"M/Y\")` returns `\"4/0\"`\n",
    "- `reformat_date(\"3/2\", \"M/D\", \"D\")` returns `\"2\"`\n",
    "\n",
    "The following examples of invalid function calls should not be tested:\n",
    "\n",
    "- `reformat_date(\"3/2\", \"M/D/Y\", \"Y/M/D\")` date string and input date format do not match\n",
    "- `reformat_date(\"3/2\", \"M/D\", \"Y/M/D\")` input date format missing a field present in the output date format\n",
    "- `reformat_date(\"1/2/3/4\", \"M/D/Y/S\", \"M/D\")` input date format contains a field that is not \"D\", \"M\", \"Y\"\n",
    "- `reformat_date(\"1/2/3\", \"M/M/Y\", \"M/Y\")` input date format contains a duplicate date symbol\n",
    "- `reformat_date(\"\", \"\", \"\")` date strings and date formats must be non-empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_date(date_string, input_format, output_format):\n",
    "    \"\"\"\n",
    "    Given a date string, an input date format that matches the date string, and an output date format\n",
    "    containing a subset of the date symbols in the input date format returns a new date string formatted\n",
    "    according to the output date format.\n",
    "    >>> reformat_date(\"12/31/1998\", \"M/D/Y\", \"D/M/Y\")\n",
    "    '31/12/1998'\n",
    "    >>> reformat_date(\"1/2/3\", \"M/D/Y\", \"Y/M/D\")\n",
    "    '3/1/2'\n",
    "    >>> reformat_date(\"0/200/4\", \"Y/D/M\", \"M/Y\")\n",
    "    '4/0'\n",
    "    >>> reformat_date(\"3/2\", \"M/D\", \"D\")\n",
    "    '2'\n",
    "    >>> reformat_date(\"1\", \"M\", \"M\")\n",
    "    '1'\n",
    "    >>> reformat_date(\"1/1/1\", \"M/D/Y\", \"M\")\n",
    "    '1'\n",
    "    >>> reformat_date(\"06/29/2005\", \"M/D/Y\", \"M\")\n",
    "    '06'\n",
    "    >>> reformat_date(\"06/29/2005\", \"M/D/Y\", \"D\")\n",
    "    '29'\n",
    "    >>> reformat_date(\"06/29/2005\", \"M/D/Y\", \"Y\")\n",
    "    '2005'\n",
    "    >>> reformat_date(\"06/29/2005\", \"M/D/Y\", \"D/M/Y\")\n",
    "    '29/06/2005'\n",
    "    \"\"\"\n",
    "    date = date_string.split('/')\n",
    "    res_date_str = \"\"\n",
    "    for i in range(len(output_format.split('/'))):\n",
    "        res_date_str += date[input_format.find(output_format[i * 2]) // 2]\n",
    "        res_date_str += \"/\"\n",
    "    res_date_str = res_date_str[:len(res_date_str) - 1]\n",
    "    return res_date_str\n",
    "doctest.run_docstring_examples(reformat_date, globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Double check that **each task has 2 of your own additional test cases**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = doctest.testmod()\n",
    "print(test_results)\n",
    "assert test_results.failed == 0, \"There are failed doctests\"\n",
    "assert test_results.attempted >= 31, \"There should be at least 31 total doctests\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
